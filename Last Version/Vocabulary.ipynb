{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMKejwGg0STSeAt6TzmI2jO"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"5vRiO1RgnV3I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"31019aa9-ca13-4c19-da7a-92d9307c44b4","executionInfo":{"status":"ok","timestamp":1591463534707,"user_tz":-180,"elapsed":23341,"user":{"displayName":"Deniz Zağlı","photoUrl":"","userId":"06848338757713536336"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tewaloEwnmg0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"dfdbb36c-5f4b-488c-8abe-8ce36905e548","executionInfo":{"status":"ok","timestamp":1591463552903,"user_tz":-180,"elapsed":1096,"user":{"displayName":"Deniz Zağlı","photoUrl":"","userId":"06848338757713536336"}}},"source":["cd drive"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KuM-UJ-UntKX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7f867721-9866-43a7-a7c4-043c025a9a4f","executionInfo":{"status":"ok","timestamp":1591463571299,"user_tz":-180,"elapsed":1146,"user":{"displayName":"Deniz Zağlı","photoUrl":"","userId":"06848338757713536336"}}},"source":["cd My\\ Drive"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0Meu4_H2nvp_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"99b79010-a088-4cc2-ef3f-dc2ce8216a07","executionInfo":{"status":"ok","timestamp":1591463602386,"user_tz":-180,"elapsed":963,"user":{"displayName":"Deniz Zağlı","photoUrl":"","userId":"06848338757713536336"}}},"source":["cd Colab\\ Notebooks"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tKcqoUm0n4Lh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"66baca19-addf-44d8-ee4e-f05575433ded","executionInfo":{"status":"ok","timestamp":1591463615953,"user_tz":-180,"elapsed":987,"user":{"displayName":"Deniz Zağlı","photoUrl":"","userId":"06848338757713536336"}}},"source":["cd Text-Style-Transfer/"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Text-Style-Transfer\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hnBvZbnnzG0i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"outputId":"8c547611-fb67-4577-8c9b-a6d5e1b113bc","executionInfo":{"status":"ok","timestamp":1591466586129,"user_tz":-180,"elapsed":9471,"user":{"displayName":"Deniz Zağlı","photoUrl":"","userId":"06848338757713536336"}}},"source":["!pip install scikit-learn==0.22"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Collecting scikit-learn==0.22\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/d0/860c4f6a7027e00acff373d9f5327f4ae3ed5872234b3cbdd7bcb52e5eff/scikit_learn-0.22-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.0MB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22) (1.18.4)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22) (0.15.1)\n","Installing collected packages: scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.22\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["sklearn"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"tnnyszUbn6uq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"b8caac7d-a8a7-4302-8a40-3056d6bfe0c0","executionInfo":{"status":"ok","timestamp":1591466955173,"user_tz":-180,"elapsed":1278,"user":{"displayName":"Deniz Zağlı","photoUrl":"","userId":"06848338757713536336"}}},"source":["import json\n","import numpy as np\n","import collections\n","import logging\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction import stop_words\n","from spacy.lang.en.stop_words import STOP_WORDS as spacy_stopwords\n","from gensim.models import KeyedVectors"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iu5zrhxNz8_6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":162},"outputId":"764077ee-a4aa-46cb-c8d3-a0ba021a16f2","executionInfo":{"status":"error","timestamp":1591466788849,"user_tz":-180,"elapsed":1883,"user":{"displayName":"Deniz Zağlı","photoUrl":"","userId":"06848338757713536336"}}},"source":["print(dir(nltk.corpus))"],"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-6de9669e858c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"]}]},{"cell_type":"code","metadata":{"id":"ssAnJkPFoAFj","colab_type":"code","colab":{}},"source":["class Vocab:\n","    def __init__(self):\n","        self.vocab_size = 9203\n","        self.train_file_path = \"update_dataset/train.txt\"\n","        self.vocab_save_path = \"update_dataset\"\n","        self.predefined_word_index = {\"<pad>\": 0, \"<sos>\": 1, \"<unk>\": 2,}\n","        self.filter_sentiment_words = True\n","        self.filter_stopwords = True\n","\n","    def create_vocab(self):\n","        index2word = dict()\n","        words = collections.Counter()\n","        word2index = self.predefined_word_index\n","        with open(self.train_file_path, 'r') as file:\n","            lines = file.readlines()\n","            for line in lines:\n","                if len(line) == 0:\n","                    continue\n","                words.update(line.split())\n","        words = words.most_common(self.vocab_size)\n","        logging.debug(\"collected {} most common words\".format(self.vocab_size))\n","        emb_matrix = np.zeros(\n","            (self.vocab_size + len(self.predefined_word_index), 300))\n","        emb_matrix[:len(self.predefined_word_index), :] = np.random.rand(\n","            len(self.predefined_word_index), 300)\n","        w2v_model = KeyedVectors.load_word2vec_format(\n","            \"word_embedding/word_embedding.txt\").wv\n","        idx = 0\n","        for word, index in self.predefined_word_index.items():\n","            word2index[word] = index\n","            index2word[index] = word\n","            idx += 1\n","        for token in words:\n","            if token[0] in w2v_model:\n","                word2index[token[0]] = idx\n","                index2word[idx] = token[0]\n","                emb_matrix[idx, :] = w2v_model[token[0]]\n","                idx = idx + 1\n","        with open(self.vocab_save_path + '/word2index.json', 'w') as json_file:\n","            json.dump(word2index, json_file)\n","        with open(self.vocab_save_path + '/index2word.json', 'w') as json_file:\n","            json.dump(index2word, json_file)\n","        np.save(\"word_embedding/word_embedding.txt\", emb_matrix)\n","        self._populate_word_blacklist(word2index)\n","\n","    def _populate_word_blacklist(self, word_index):\n","        blacklisted_words = set()\n","        bow_filtered_vocab_indices = dict()\n","        blacklisted_words |= set(self.predefined_word_index.values())\n","        if self.filter_sentiment_words:\n","            blacklisted_words |= self._get_sentiment_words()\n","        if self.filter_stopwords:\n","            blacklisted_words |= self._get_stopwords()\n","        allowed_vocab = word_index.keys() - blacklisted_words\n","        i = 0\n","        for word in allowed_vocab:\n","            vocab_index = word_index[word]\n","            bow_filtered_vocab_indices[vocab_index] = i\n","            i += 1\n","        print(\"BoW_Size: \" + str(len(allowed_vocab)))\n","        with open(self.vocab_save_path + '/bow.json', 'w') as json_file:\n","            json.dump(bow_filtered_vocab_indices, json_file)\n","\n","    def _get_sentiment_words(self):\n","        with open(file=\"dataset/train.0\",\n","                  mode='r', encoding='ISO-8859-1') as pos_sentiment_words_file,\\\n","            open(file=\"dataset/train.0\",\n","                 mode='r', encoding='ISO-8859-1') as neg_sentiment_words_file:\n","            pos_words = pos_sentiment_words_file.readlines()\n","            neg_words = neg_sentiment_words_file.readlines()\n","            words = pos_words + neg_words\n","        words = set(word.strip() for word in words)\n","        return words\n","\n","    def _get_stopwords(self):\n","        nltk_stopwords = set(stopwords.words('english'))\n","        sklearn_stopwords = stop_words.ENGLISH_STOP_WORDS\n","        all_stopwords = set()\n","        all_stopwords |= spacy_stopwords\n","        all_stopwords |= nltk_stopwords\n","        all_stopwords |= sklearn_stopwords\n","        return all_stopwords"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1TEHOtKQoZPh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"3f4e3508-5220-420c-a290-4e3ee6d37ad7","executionInfo":{"status":"ok","timestamp":1591467017942,"user_tz":-180,"elapsed":5548,"user":{"displayName":"Deniz Zağlı","photoUrl":"","userId":"06848338757713536336"}}},"source":["vocab = Vocab()\n","vocab.create_vocab()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"],"name":"stderr"},{"output_type":"stream","text":["BoW_Size: 8886\n"],"name":"stdout"}]}]}